# Geomarketing{#location}

```{r, include=FALSE}
source("code/before_script.R")
```

## Wymagania wstępne{-}

- Ten rozdział wymaga następujących pakietów (należy również zainstalować**tmaptools**):

```{r 14-location-1, message=FALSE}
library(sf)
library(dplyr)
library(purrr)
library(terra)
library(osmdata)
library(spDataLarge)
```

- Wymagane dane zostaną pobrane w odpowiednim czasie.

Dla wygody czytelnika i w celu zapewnienia łatwej powtarzalności udostępniliśmy pobrane dane wpakiecie**spDataLarge**.

## Wprowadzenie

W niniejszym rozdziale pokazano, w jaki sposób umiejętności nabyte w częściach I i II można zastosować w konkretnej dziedzinie: geomarketingu\\index{geomarketing}(czasami nazywanym również analizą lokalizacji\\index{location analysis}lub analizą lokalizacji).Jest
to szeroka dziedzina badań i zastosowań komercyjnych.Typowym
przykładem geomarketingu jest lokalizacja nowego sklepu.
Celem jest tutaj przyciągnięcie jak największej liczby klientów i ostatecznie osiągnięcie jak największego zysku.
 Istnieje również wiele zastosowań niekomercyjnych, które mogą wykorzystywać tę technikę dla dobra publicznego, na przykład przy wyborze lokalizacji nowych placówek służby zdrowia [@tomintz_geography_2008] .

Ludzie mają fundamentalne znaczenie dla analizy lokalizacji\\index{location analysis}, w szczególności w odniesieniu do miejsc

,

w których prawdopodobnie spędzają czas i wykorzystują inne zasoby.
Co ciekawe, koncepcje i modele ekologiczne są dość podobne do tych stosowanych w analizie lokalizacji sklepów.
Zwierzęta i rośliny mogą najlepiej zaspokajać swoje potrzeby w określonych „optymalnych” lokalizacjach, w oparciu o zmienne, które zmieniają się w przestrzeni (@muenchow\_review\_2018; zob. również rozdział @ref(eco)).Jest
to jedna z największych zalet geokomputacji i nauk o systemach informacji geograficznej (GIScience) w ogóle: koncepcje i metody można przenieść na inne dziedziny.
Na przykład niedźwiedzie polarne preferują północne szerokości geograficzne, gdzie temperatury są niższe, a pożywienie (foki i lwy morskie) jest obfite.
Podobnie ludzie mają tendencję do gromadzenia się w określonych miejscach, tworząc nisze ekonomiczne (i wysokie ceny gruntów) analogiczne do niszy ekologicznej Arktyki.
Głównym zadaniem analizy lokalizacji jest ustalenie, na podstawie dostępnych danych, gdzie znajdują się takie „optymalne lokalizacje” dla określonych usług.
Typowe pytania badawcze obejmują:

- Gdzie mieszkają grupy docelowe i jakie obszary najczęściej odwiedzają?
- Gdzie znajdują się konkurencyjne sklepy lub usługi?
- Ile osób ma łatwy dostęp do konkretnych sklepów?
- Czy istniejące usługi wykorzystują potencjał rynku w nadmiernym lub niewystarczającym stopniu?
- Jaki jest udział firmy w rynku w konkretnym obszarze?

W niniejszym rozdziale pokazano, w jaki sposób geokomputacja może odpowiedzieć na takie pytania w oparciu o hipotetyczne studium przypadku i rzeczywiste dane.

## Studium przypadku: sklepy rowerowe w Niemczech{#case-study}

Wyobraź sobie, że otwierasz sieć sklepów rowerowych w Niemczech.
Sklepy powinny być zlokalizowane w obszarach miejskich, gdzie znajduje się jak najwięcej potencjalnych klientów.
Dodatkowo, hipotetyczna ankieta (wymyślona na potrzeby tego rozdziału, nie do użytku komercyjnego!) sugeruje, że najprawdopodobniej Twoje produkty kupią samotni młodzi mężczyźni (w wieku od 20 do 40 lat): to jest*grupa**docelowa*.
Masz szczęście, ponieważ dysponujesz wystarczającym kapitałem, aby otworzyć kilka sklepów.
Ale gdzie je umieścić?
Firmy konsultingowe (zatrudniająceanalitykówgeomarketingowych\\index{geomarketing}) chętnie pobierają wysokie opłaty za udzielenie odpowiedzi na takie pytania.
Na szczęście możemy to zrobić samodzielnie, korzystając z otwartych danych\\index{open data}i oprogramowania open source\\index{open source software}.
W kolejnych sekcjach pokażemy,jak techniki poznane w pierwszych rozdziałach książki można zastosować do wykonania typowych czynności związanych z analizą lokalizacji usług:

- Uporządkuj dane wejściowe z niemieckiego spisu ludności (sekcja @ref(tidy-the-input-data))
- Przekształć tabelaryczne dane spisu ludności naobiektyrastrowe\\index{raster}(sekcja @ref(create-census-rasters))
- Zidentyfikuj obszary metropolitalne o wysokiej gęstości zaludnienia (sekcja @ref(define-metropolitan-areas))
- Pobierz szczegółowe dane geograficzne (z OpenStreetMap\\index{OpenStreetMap}, za pomocą**osmdata**\\index{osmdata (package)}) dla tych obszarów (sekcja @ref(points-of-interest))
- Utwórz rastrowe\\index{raster}do oceny względnej atrakcyjności różnych lokalizacji za pomocą map algebra\\index{map algebra}(sekcja @ref(create-census-rasters))

Chociaż zastosowaliśmy te kroki do konkretnego studium przypadku, można je uogólnić do wielu scenariuszy lokalizacji sklepów lub świadczenia usług publicznych.

## Uporządkuj dane wejściowe

Rząd niemiecki udostępnia dane spisu ludności w postaci siatki o rozdzielczości 1 km lub 100 m.
Poniższy fragment kodu pobiera, rozpakowuje i odczytuje dane o rozdzielczości 1 km.

```{r 14-location-2, eval=FALSE}
download.file("https://tinyurl.com/ybtpkwxz", 
              destfile = "census.zip", mode = "wb")
unzip("census.zip") # unzip the files
census_de = readr::read_csv2(list.files(pattern = "Gitter.csv"))
```

Należy pamiętać, że`census_de`jest również dostępny wpakiecie**spDataLarge**:

```{r attach-census}
data("census_de", package = "spDataLarge")
```

Obiekt`census_de`jest ramką danych zawierającą 13 zmiennych dla ponad 360 000 komórek siatki w całych Niemczech.
Do naszej pracy potrzebujemy tylko podzbioru tych danych: współrzędna wschodnia (`x`) i współrzędna północna (`y`), liczba mieszkańców (populacja;`pop`), średnia wieku (`mean_age`), odsetek kobiet (`women`) oraz średnia wielkość gospodarstwa domowego (`hh_size`).
Zmienne te zostały wybrane i przemianowane z języka niemieckiego na angielski w poniższym fragmencie kodu i podsumowane w tabeli @ref(tab:census-desc).
Ponadtoza pomocą



funkcji`mutate()`wartości`-1`i`-9`(oznaczające „nieznane”)zostały zamienionena`NA`.

```{r 14-location-4}
# pop = population, hh_size = household size
input = select(census_de, x = x_mp_1km, y = y_mp_1km, pop = Einwohner,
                      women = Frauen_A, mean_age = Alter_D, hh_size = HHGroesse_D)
# set -1 and -9 to NA
input_tidy = mutate(input, across(.cols = c(pop, women, mean_age, hh_size), 
                                  .fns =  ~ifelse(.x %in% c(-1, -9), NA, .x)))
```

```{r census-desc, echo=FALSE}
tab = dplyr::tribble(
  ~"class", ~"pop", ~"women", ~"age", ~"hh",
  1, "3-250", "0-40", "0-40", "1-2", 
  2, "250-500", "40-47", "40-42", "2-2.5",
  3, "500-2000", "47-53", "42-44", "2.5-3",
  4, "2000-4000", "53-60", "44-47", "3-3.5",
  5, "4000-8000", ">60", ">47", ">3.5",
  6, ">8000", "", "", ""
)
# commented code to show the input data frame with factors (RL):
# summary(input_tidy) # all integers
# fct_pop = factor(input_tidy$pop, labels = tab$pop)
# summary(fct_pop)
# sum(is.na(input_tidy$pop))
# fct_women = factor(input_tidy$women, labels = tab$women[1:5])
# summary(fct_women)
# sum(is.na(input_tidy$women))
# fct_mean_age = factor(input_tidy$mean_age, labels = tab$age[1:5])
# summary(fct_mean_age)
# sum(is.na(input_tidy$mean_age))
# fct_hh_size = factor(input_tidy$hh_size, labels = tab$hh[1:5])
# summary(fct_hh_size)
# sum(is.na(input_tidy$hh_size))
# input_factor = bind_cols(
#   select(input_tidy, 1:2),
#   pop = fct_pop,
#   women = fct_women,
#   mean_age = fct_mean_age,
#   hh_size = fct_hh_size,
# )
# summary(input_factor)
cap = paste("Categories for each variable in census data from",
            "Datensatzbeschreibung...xlsx", 
            "located in the downloaded file census.zip.")
knitr::kable(tab,
             col.names = c("Class", "Population", "% Female", "Mean Age",
                           "Household Size"),
             caption = cap, 
             caption.short = "Categories for each variable in census data.",
             align = "c", booktabs = TRUE)
```

## Tworzenie rastrów spisu ludności

Po przetworzeniu wstępnym dane można przekształcić wobiekt`SpatRaster`(patrz sekcje @ref(raster-classes) i @ref(raster-subsetting)) za pomocąfunkcji`rast()`.
Po ustawieniuargumentu`type`na`xyz`kolumny`x`i`y`ramki danych wejściowych powinny odpowiadać współrzędnym na regularnej siatce.
Wszystkie pozostałe kolumny (tutaj:`pop`,`women`,`mean_age`,`hh_size`) będą służyć jako wartości warstw rastrowych (rysunek @ref(fig:census-stack); zobacz także`code/14-location-figures.R`w naszym repozytorium GitHub).

```{r 14-location-5}
input_ras = rast(input_tidy, type = "xyz", crs = "EPSG:3035")
```

```{r 14-location-6}
input_ras
```

```{block2 14-location-7, type="rmdnote"}
Note that we are using an equal-area projection (EPSG:3035; Lambert Equal Area Europe), i.e., a projected CRS\index{CRS!projected} where each grid cell has the same area, here 1000 * 1000 square meters. 
Since we are using mainly densities such as the number of inhabitants or the portion of women per grid cell, it is of utmost importance that the area of each grid cell is the same to avoid 'comparing apples and oranges'.
Be careful with geographic CRS\index{CRS!geographic} where grid cell areas constantly decrease in poleward directions (see also Section \@ref(crs-intro) and Chapter \@ref(reproj-geo-data)).
```

```{r census-stack, echo=FALSE, fig.cap="Gridded German census data of 2011 (see Table 14.1 for a description of the classes).", fig.scap="Gridded German census data."}
knitr::include_graphics("images/14_census_stack.png")
```

Kolejnym etapem jest reklasyfikacja wartości rastrów przechowywanych w`input_ras`zgodnie z badaniem wspomnianym w sekcji @ref(case-study), przy użyciufunkcji**terra**`classify()`, która została wprowadzona w sekcji @ref(local-operations)\\index{map algebra!local operations}.
W przypadku danych dotyczących populacji przekształcamy klasy na typ danych numerycznych przy użyciu średnich klasowych.
Komórki rastrowe mają populację 127, jeśli mają wartość 1 (komórki w „klasie 1” zawierają od 3 do 250 mieszkańców) i 375, jeśli mają wartość 2 (zawierają od 250 do 500 mieszkańców) itd. (patrz tabela @ref(tab:census-desc)).
Wartość komórki 8000 mieszkańców została wybrana dla „klasy 6”, ponieważ komórki te zawierają ponad 8000 osób.
Oczywiście są to przybliżenia rzeczywistej liczby ludności, a nie wartości dokładne.^\[
Potencjalny błąd wprowadzony na etapie reklasyfikacji zostanie zbadany w ćwiczeniach.
\]
Jednak poziom szczegółowości jest wystarczający do wyznaczenia obszarów metropolitalnych (patrz sekcja @ref(define-metropolitan-areas)).

W przeciwieństwie dozmiennej`pop`, reprezentującej bezwzględne szacunki całkowitej liczby ludności, pozostałe zmienne zostały przeklasyfikowane jako wagi odpowiadające wagom używanym w badaniu.
Na przykładklasa 1 w zmiennej`women`reprezentuje obszary, w których od 0 do 40% populacji stanowią kobiety;są
one przeklasyfikowane z stosunkowo wysoką wagą 3,ponieważ docelowa grupa demograficzna składa się głównie z mężczyzn.
Podobnie klasy zawierające najmłodsze osoby i najwyższy odsetek gospodarstw jednoosobowych są przeklasyfikowane tak, aby miały wysokie wagi.

```{r 14-location-8}
rcl_pop = matrix(c(1, 1, 127, 2, 2, 375, 3, 3, 1250, 
                   4, 4, 3000, 5, 5, 6000, 6, 6, 8000), 
                 ncol = 3, byrow = TRUE)
rcl_women = matrix(c(1, 1, 3, 2, 2, 2, 3, 3, 1, 4, 5, 0), 
                   ncol = 3, byrow = TRUE)
rcl_age = matrix(c(1, 1, 3, 2, 2, 0, 3, 5, 0),
                 ncol = 3, byrow = TRUE)
rcl_hh = rcl_women
rcl = list(rcl_pop, rcl_women, rcl_age, rcl_hh)
```

Należy zauważyć

,

że upewniliśmy się

,

że kolejność macierzy przeklasyfikowania na liście jest taka sama jak w przypadku elementów`input_ras`.
Na przykład pierwszy element odpowiada w obu przypadkach populacji.
Następnie pętla`for`\-loop\\index{loop!for}stosuje macierz reklasyfikacji do odpowiedniej warstwy rastrowej.
Na koniec poniższy fragment kodu zapewnia, żewarstwy`reclass`mają taką samą nazwę jak warstwy`input_ras`.

```{r 14-location-9}
reclass = input_ras
for (i in seq_len(nlyr(reclass))) {
  reclass[[i]] = classify(x = reclass[[i]], rcl = rcl[[i]], right = NA)
}
names(reclass) = names(input_ras)
```



```{r 14-location-10, eval=FALSE}
reclass # full output not shown
#> ... 
#> names       :  pop, women, mean_age, hh_size 
#> min values  :  127,     0,        0,       0 
#> max values  : 8000,     3,        3,       3
```

## Zdefiniowanie obszarów metropolitalnych

Celowo definiujemy obszary metropolitalne jako piksele o powierzchni 20 km^2^ zamieszkane przez ponad 500 000 osób.
Piksele o tak niskiej rozdzielczości można szybko utworzyć za pomocą polecenia`aggregate()`\\index{aggregation}, jak przedstawiono w sekcji @ref(aggregation-and-disaggregation).Poniższe
polecenie wykorzystuje argument`fact = 20`w celu zmniejszenia rozdzielczości wyniku 20-krotnie (przypomnijmy, że pierwotna rozdzielczość rastra wynosiła 1 km^2^).

```{r 14-location-11, warning=FALSE, cache=TRUE, cache.lazy=FALSE}
pop_agg = aggregate(reclass$pop, fact = 20, fun = sum, na.rm = TRUE)
summary(pop_agg)
```

Kolejnym etapem jest zachowanie tylko komórek, w których mieszka ponad pół miliona osób.

```{r 14-location-12, warning=FALSE, cache.lazy=FALSE, cache=TRUE}
pop_agg = pop_agg[pop_agg > 500000, drop = FALSE] 
```

Wynikiem tego jest ośmiu regionów metropolitalnych (rysunek @ref(fig:metro-areas)).
Każdy region składa się z jednej lub więcej komórek rastrowych.
Byłoby dobrze, gdybyśmy mogli połączyć wszystkie komórki należące do jednego regionu.
Polecenie**terra**'s\\index{terra (package)}`patches()`właśnie to robi.
Następnie polecenie`as.polygons()`konwertuje obiekt rastrowy na wielokąty przestrzenne, apolecenie`st_as_sf()`konwertuje go naobiekt`sf`.

Polecenie



```{r 14-location-13, warning=FALSE, message=FALSE}
metros = pop_agg |> 
  patches(directions = 8) |>
  as.polygons() |>
  st_as_sf()
```



```{r metro-areas, echo=FALSE, out.width="70%", fig.cap="The aggregated population raster (resolution: 20 km) with the identified metropolitan areas (golden polygons) and the corresponding names.", fig.scap="The aggregated population raster."}
knitr::include_graphics("images/14_metro_areas.png")
```

Otrzymane w ten sposób osiem obszarów metropolitalnych odpowiednich dla sklepów rowerowych (rysunek @ref(fig:metro-areas); zobacz także`code/14-location-figures.R`dotyczące tworzenia rysunku) nadal nie ma nazwy.Problem ten
można rozwiązać za pomocąodwrotnego geokodowania\\index{geocoding}: na podstawie współrzędnych znajduje ono odpowiedni adres.
W związku z tym wyodrębnieniewspółrzędnychcentroid\\index{centroid}każdego obszaru metropolitalnego może posłużyć jako dane wejściowe dla odwrotnego geokodowania API\\index{API}.Jest
to dokładnie to, czegooczekujefunkcja`rev_geocode_OSM()`pakietu**tmaptools**.
Dodatkowe ustawienie`as.data.frame`na`TRUE`zwróci`data.frame`z kilkoma kolumnami odnoszącymi się do lokalizacji, w tym nazwą ulicy, numerem domu i miastem.
Jednak w tym przypadku interesuje nas tylko nazwa miasta.

```{r 14-location-17, warning=FALSE, eval=FALSE}
metro_names = sf::st_centroid(metros, of_largest_polygon = TRUE) |>
  tmaptools::rev_geocode_OSM(as.data.frame = TRUE) |>
  select(city, town, state)
# smaller cities are returned in column town. To have all names in one column,
# we move the town name to the city column in case it is NA
metro_names = dplyr::mutate(metro_names, city = ifelse(is.na(city), town, city))
```

Aby mieć pewność, że czytelnik korzysta z dokładnie tych samych wyników, umieściliśmy je w**spDataLarge**jako obiekt`metro_names`.

```{r metro-names, echo=FALSE}
data("metro_names", package = "spDataLarge")
knitr::kable(select(metro_names, City = city, State = state), 
             caption = "Result of the reverse geocoding.", 
             caption.short = "Result of the reverse geocoding.", 
             booktabs = TRUE)
```

Ogólnie jesteśmy zadowoleni zkolumny`City`służącej jako nazwy metropolii (Tabela @ref(tab:metro-names)),z jednym wyjątkiem, a mianowicie Velbert,które należy do większego regionu Düsseldorfu.
Dlatego zastępujemy Velbert Düsseldorfem (Rysunek @ref(fig:metro-areas)).
Umlauty, takie jak`ü`, mogą powodować problemy w dalszej części, na przykład podczas określania granicy obszaru metropolitalnego za pomocą`opq()`(patrz dalej), dlatego ich unikamy.

```{r 14-location-19}
metro_names = metro_names$city |> 
  as.character() |>
  (\(x) ifelse(x == "Velbert", "Düsseldorf", x))() |>
  gsub("ü", "ue", x = _)
```

## Punkty zainteresowania

\\index{point of interest}
Pakiet**osmdata**\\index{osmdata (package)}zapewnia łatwy dostęp dodanychOSM\\index{OpenStreetMap}(zobacz także sekcję @ref(retrieving-data)).
Zamiast pobierać dane dotyczące sklepów z całych Niemiec, ograniczamy zapytanie do określonych obszarów metropolitalnych, zmniejszając obciążenie obliczeniowe i dostarczając lokalizacje sklepów tylko w obszarach będących przedmiotem zainteresowania.
Poniższy fragment kodu realizuje to za pomocą szeregu funkcji, w tym:

- `map()`\\index{loop!map}(odpowiednik**tidyverse**dla`lapply()`\\index{loop!lapply}), która iteruje przez wszystkie osiem nazw obszarów metropolitalnych, które następnie definiują obszar ograniczający\\index{bounding box}wfunkcji zapytaniaOSM\\index{OpenStreetMap}`opq()`(patrz sekcja @ref(retrieving-data))
- `add_osm_feature()`w celu określeniaelementówOSM\\index{OpenStreetMap}o wartości klucza`shop`(lista popularnych par klucz:wartośćznajduje sięnastronie[wiki.openstreetmap.org](https://wiki.openstreetmap.org/wiki/Map_Features))
- `osmdata_sf()`, która konwertujedaneOSM\\index{OpenStreetMap}na obiekty przestrzenne (klasy`sf`)
- `while()`\\index{loop!while}, która podejmuje dwie kolejne próby pobrania danych, jeśli pierwsza próba zakończyła się niepowodzeniem^\[Pobieranie danych OSM czasami kończy się niepowodzeniem przy pierwszej próbie.
  \]

Przed uruchomieniem tego kodu należy wziąć pod uwagę, że spowoduje on pobranie prawie dwóch GB danych.
Aby zaoszczędzić czas i zasoby, umieściliśmy wynik o nazwie`shops`w**spDataLarge**.
Aby udostępnić go w swoim środowisku, uruchom`data("shops", package = "spDataLarge")`.

```{r 14-location-20, eval=FALSE, message=FALSE}
shops = purrr::map(metro_names, function(x) {
  message("Downloading shops of: ", x, "\n")
  # give the server a bit time
  Sys.sleep(sample(seq(5, 10, 0.1), 1))
  query = osmdata::opq(x) |>
    osmdata::add_osm_feature(key = "shop")
  points = osmdata::osmdata_sf(query)
  # request the same data again if nothing has been downloaded
  iter = 2
  while (nrow(points$osm_points) == 0 && iter > 0) {
    points = osmdata_sf(query)
    iter = iter - 1
  }
  # return only the point features
  points$osm_points
})
```

Jest bardzo mało prawdopodobne, aby w żadnym z naszych zdefiniowanych obszarów metropolitalnych nie było żadnych sklepów.
Poniższywarunek`if`sprawdza po prostu, czy w każdym regionie znajduje się co najmniej jeden sklep.
Jeśli nie, zalecamy ponowne pobranie sklepów dla tego konkretnego regionu/regionów.

```{r 14-location-21, eval=FALSE}
# checking if we have downloaded shops for each metropolitan area
ind = purrr::map_dbl(shops, nrow) == 0
if (any(ind)) {
  message("There are/is still (a) metropolitan area/s without any features:\n",
          paste(metro_names[ind], collapse = ", "), "\nPlease fix it!")
}
```

Aby upewnić się, że każdy element listy ( ramka danych`sf`\\index{sf} ) ma te same kolumny^ [Nie jest to oczywiste] , [ponieważ autorzy OSM nie są równie skrupulatni podczas gromadzenia danych.] Zachowujemy tylkokolumny`osm_id`i`shop`za pomocąpętli`map_dfr` ,która dodatkowo łączy wszystkie sklepy w jeden dużyobiekt`sf`\\index{sf}.

```{r 14-location-22, eval=FALSE}
# select only specific columns
shops = purrr::map_dfr(shops, select, osm_id, shop)
```

Uwaga:`shops`jest dostępny w`spDataLarge`i można uzyskać do niego dostęp w następujący sposób:

```{r attach-shops}
data("shops", package = "spDataLarge")
```

Jedyne, co pozostało do zrobienia, to przekształcenie obiektu punktowego w raster (patrz sekcja @ref(rasterization)).
Obiekt`sf`,`shops`, jest przekształcany w raster\\index{raster}o tych samych parametrach (wymiarach, rozdzielczości, CRS\\index{CRS}) coobiekt`reclass`.
Co ważne,funkcja`length()`jest tutaj używana do zliczenia liczby sklepów w każdej komórce.

Wynikiem kolejnego fragmentu kodu jest zatem oszacowanie gęstości sklepów (sklepy/km^2^).
`st_transform()`\\index{sf!st\_transform}jest używane przed`rasterize()`\\index{raster!rasterize}, aby zapewnićzgodnośćCRS\\index{CRS}obu danych wejściowych.

```{r tmmppp21, echo=FALSE, message=FALSE, warning=FALSE}
shops = sf::st_transform(shops, st_crs(reclass))
# create point of interest (poi) raster
poi = rasterize(x = vect(shops), y = reclass, field = "osm_id", fun = "length")
```

```{r 14-location-25, message=FALSE, warning=FALSE, eval=FALSE}
shops = sf::st_transform(shops, st_crs(reclass))
# create poi raster
poi = rasterize(x = shops, y = reclass, field = "osm_id", fun = "length")
```

Podobnie jak w przypadku innych warstw rastrowych (populacja, kobiety, średni wiek, wielkość gospodarstwa domowego),raster`poi`jest przeklasyfikowywany do czterech klas (patrz sekcja @ref(create-census-rasters)).
Określenie przedziałów klas jest w pewnym stopniu arbitralnym przedsięwzięciem.
Można użyć równych przedziałów, przedziałów kwantylowych, wartości stałych lub innych.
W tym przypadku wybieramy podejście naturalnych przedziałów Fishera-Jenksa, które minimalizuje wariancję wewnątrzklasową, a wynik stanowi dane wejściowe dla macierzy reklasyfikacji.

```{r 14-location-26, message=FALSE, warning=FALSE}
# construct reclassification matrix
int = classInt::classIntervals(values(poi), n = 4, style = "fisher")
int = round(int$brks)
rcl_poi = matrix(c(int[1], rep(int[-c(1, length(int))], each = 2), 
                   int[length(int)] + 1), ncol = 2, byrow = TRUE)
rcl_poi = cbind(rcl_poi, 0:3)  
# reclassify
poi = classify(poi, rcl = rcl_poi, right = NA) 
names(poi) = "poi"
```

## Zidentyfikuj odpowiednie lokalizacje

Jedyne kroki, które pozostały przed połączeniem wszystkich warstw, to dodanie`poi`dostosu rastrowe`reclass`i usunięcie z niego warstwy populacji.
Powody tego ostatniego są następujące: po pierwsze, wyznaczyliśmy już obszary metropolitalne, czyli obszary, w których gęstość zaludnienia jest powyżej średniej w porównaniu z resztą Niemiec.
Po drugie, choć korzystne jest posiadanie wielu potencjalnych klientów w określonym obszarze oddziaływania\\index{catchment area}, sama liczba może nie odzwierciedlać pożądanej grupy docelowej.
Na przykład wieżowce mieszkalne są obszarami o dużej gęstości zaludnienia, ale niekoniecznie o dużej sile nabywczej w zakresie drogich komponentów rowerowych.

```{r 14-location-27}
# remove population raster and add poi raster
reclass = reclass[[names(reclass) != "pop"]] |>
  c(poi)
```

Podobnie jak w przypadku innych projektów z zakresu nauki o danych, dotychczas większość pracy zajęło pozyskiwanie i „porządkowanie” danych.
Dzięki czystym danym ostatni etap — obliczenie końcowego wyniku poprzez zsumowanie wszystkichwarstwrastrowo-indeksowych{raster}— można wykonać za pomocą jednego wiersza kodu.

```{r 14-location-28}
# calculate the total score
result = sum(reclass)
```

Na przykład wynik powyżej 9 może być odpowiednim progiem wskazującym komórki rastrowe, w których można umieścić sklep rowerowy (rysunek @ref(fig:bikeshop-berlin); zob. również`code/14-location-figures.R`).

```{r bikeshop-berlin, echo=FALSE, eval=TRUE, fig.cap="Suitable areas (i.e., raster cells with a score > 9) in accordance with our hypothetical survey for bike stores in Berlin.", fig.scap="Suitable areas for bike stores.", warning=FALSE}
if (knitr::is_latex_output()) {
    knitr::include_graphics("images/bikeshop-berlin-1.png")
} else if (knitr::is_html_output()) {
    library(leaflet)
    # have a look at suitable bike shop locations in Berlin
    berlin = metros[metro_names == "Berlin", ]
    berlin_raster = crop(result, vect(berlin)) 
    # summary(berlin_raster)
    # berlin_raster
    berlin_raster = berlin_raster[berlin_raster > 9, drop = FALSE]
    leaflet::leaflet() |> 
      leaflet::addTiles() |>
      # addRasterImage so far only supports raster objects
      leaflet::addRasterImage(raster::raster(berlin_raster), colors = "darkgreen",
                              opacity = 0.8) |>
      leaflet::addLegend("bottomright", colors = c("darkgreen"), 
                         labels = c("potential locations"), title = "Legend")  
}
```

## Dyskusja i kolejne kroki

Przedstawione podejście jest typowym przykładem normatywnego wykorzystania GIS\\index{GIS} [@longley_geographic_2015] .
Połączyliśmy dane ankietowe z wiedzą i założeniami ekspertów (definicja obszarów metropolitalnych, definiowanie przedziałów klasowych, definiowanie progu końcowego wyniku).
Podejście to jest mniej odpowiednie dla badań naukowych niż analiza stosowana, która dostarcza oparte na dowodach wskazania obszarów odpowiednich dla sklepów rowerowych, które należy porównać z innymi źródłami informacji.
Szereg zmian w podejściu mogłoby poprawić analizę:

- przy obliczaniu wyników końcowych zastosowaliśmy równe wagi, ale inne czynniki, takie jak wielkość gospodarstwa domowego, mogą być równie ważne jak odsetek kobiet lub średnia wieku.
- Wykorzystaliśmy wszystkie punkty zainteresowania\\index{point of interest}, ale tylko te związane ze sklepami rowerowymi, takimi jak sklepy z artykułami do majsterkowania, sprzętem, rowerami, wędkarstwem, łowiectwem, motocykle, sklepy outdoorowe i sportowe (zobacz zakres wartości sklepów dostępnych na  [OSM Wiki](https://wiki.openstreetmap.org/wiki/Map_Features#Shop)) mogłyby dać bardziej precyzyjne wyniki
- . Dane o wyższej rozdzielczości mogą poprawić wynik (zobacz Ćwiczenia)
- . Wykorzystaliśmy tylko ograniczony zestaw zmiennych, a dane z innych źródeł, takich jak[geoportal](https://inspire-geoportal.ec.europa.eu/)[INSPIRE](https://inspire-geoportal.ec.europa.eu/)lub dane o ścieżkach rowerowych z OpenStreetMap, mogą wzbogacić analizę (zobacz również sekcję @ref(retrieving-data)).
- Nie uwzględniono interakcji, takich jak możliwy związek między odsetkiem mężczyzn a gospodarstwami jednoosobowymi

. Krótko mówiąc, analizę można rozszerzyć w wielu kierunkach.
Niemniej jednak powinna ona dać Państwu pierwsze wrażenie i zrozumienie, jak uzyskać i przetwarzać dane przestrzenne w R\\index{R}wkontekściegeomarketingu\\index{geomarketing}.

Na koniec musimy zaznaczyć, że przedstawiona analiza byłaby jedynie pierwszym krokiem do znalezienia odpowiednich lokalizacji.
Do tej pory zidentyfikowaliśmy obszary o wielkości 1 na 1 km, które zgodnie z naszą ankietą stanowią potencjalnie odpowiednie lokalizacje dla sklepu rowerowego.
Kolejne kroki w analizie mogą obejmować:

- Znalezienie optymalnej lokalizacji na podstawie liczby mieszkańców w określonym obszarze oddziaływania\\index{catchment area}.
  Na przykład sklep powinien być dostępny dla jak największej liczby osób w ciągu 15 minut jazdy rowerem (obszar oddziaływania\\index{catchment area}routing\\index{routing}).
  Należy przy tym wziąć pod uwagę fakt, że im dalej ludzie mieszkają od sklepu, tym mniejsze jest prawdopodobieństwo, że faktycznie go odwiedzą (funkcja spadku odległości)
- . Dobrym pomysłem byłoby również uwzględnienie konkurencji.
   Oznacza to, że jeśli w pobliżu wybranej lokalizacji znajduje się już sklep rowerowy, potencjalni klienci (lub potencjał sprzedaży) powinni zostać rozdzieleni między konkurentów [@huff_probabilistic_1963; @wieland_market_2017]
- Musimy znaleźć odpowiednią i przystępną cenowo nieruchomość, np. pod względem dostępności, dostępności miejsc parkingowych, pożądanej częstotliwości przechodniów, dużych okien itp.

## Ćwiczenia

```{r, echo=FALSE, results="asis"}
res = knitr::knit_child('_14-ex.Rmd', quiet = TRUE, options = list(include = FALSE, eval = FALSE))
cat(res, sep = '\n')
```


